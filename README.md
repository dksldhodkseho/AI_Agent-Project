# ğŸ¤– AI ë©´ì ‘ê´€ Agent

ìê¸°ì†Œê°œë¥¼ ì…ë ¥í•˜ë©´ **AIê°€ ì‹¤ì œ ë©´ì ‘ì²˜ëŸ¼ ì§ˆë¬¸í•˜ê³ **,  
**ë‹µë³€ì„ í‰ê°€í•˜ë©° í”¼ë“œë°±ê³¼ ì ìˆ˜ë¥¼ ì œê³µí•˜ëŠ” AI ë©´ì ‘ ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤.

---

## ğŸ—‚ï¸ í”„ë¡œì íŠ¸ ê°œìš”

- **ëª©í‘œ**:  
  ì‚¬ìš©ìì˜ ìê¸°ì†Œê°œì„œë¥¼ ì…ë ¥ë°›ì•„, AIê°€ **ì‹¬ì¸µ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³ **,  
  ì‚¬ìš©ìì˜ ë‹µë³€ì„ **ìë™ í‰ê°€ ë° ì ìˆ˜í™”**, **ê°œì„  í”¼ë“œë°±**ê¹Œì§€ ì œê³µí•©ë‹ˆë‹¤.

- **ì‚¬ìš© ê¸°ìˆ **:  
  `Python`, `OpenAI GPT-3.5-turbo`, `Streamlit`

- **íŒ€ëª…**: AI 01ë°˜ 2ì¡°  
- **íŒ€ì›**: ìµœì¸ê·œ, ì†ì •í›„, ê¹€ì„œì˜, ì˜¤ìŠ¹í›ˆ, ì§€ìš©ì£¼, ì¡°ì‹œí˜„

---

## ğŸ§  ì‹œìŠ¤í…œ êµ¬ì¡°

AI ë©´ì ‘ê´€ì˜ ì „ì²´ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

![ì‹œìŠ¤í…œ êµ¬ì¡°ë„](./assets/ai_interview_pipeline.png)

> ìê¸°ì†Œê°œ â†’ AI ì§ˆë¬¸ ìƒì„± â†’ ë‹µë³€ ì…ë ¥ â†’ í”¼ë“œë°± ì œê³µ â†’ ì ìˆ˜í™”

---

## ğŸ§© í•µì‹¬ ê¸°ëŠ¥ ë° ì½”ë“œ

ê° ê¸°ëŠ¥ì„ ê°œë³„ ëª¨ë“ˆë¡œ êµ¬í˜„í•˜ì—¬ GPT APIë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í–ˆìŠµë‹ˆë‹¤.

---

### 1ï¸âƒ£ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜

```python
def generate_question(user_intro):
    prompt = f"ì•„ë˜ ìê¸°ì†Œê°œë¥¼ ì°¸ê³ í•˜ì—¬ ì§€ì›ìì—ê²Œ ë˜ì§ˆ ì‹¬ì¸µì ì¸ ë©´ì ‘ ì§ˆë¬¸ í•œ ê°€ì§€ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.\n\nìê¸°ì†Œê°œ: {user_intro}\n\në©´ì ‘ ì§ˆë¬¸:"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë›°ì–´ë‚œ ë©´ì ‘ê´€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=150
    )
    return response.choices[0].message['content'].strip()
```
âœ… ì‚¬ìš©ìì˜ ìê¸°ì†Œê°œë¥¼ ê¸°ë°˜ìœ¼ë¡œ AIê°€ ì ì ˆí•œ ë©´ì ‘ ì§ˆë¬¸ì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤.

### 2ï¸âƒ£ ë‹µë³€ í‰ê°€ ë° í”¼ë“œë°± í•¨ìˆ˜
```python
def evaluate_answer(user_answer):
    prompt = f"ì§€ì›ìì˜ ë‹µë³€ì„ í‰ê°€í•˜ê³  ê°œì„ ì ì„ ê°„ë‹¨í•˜ê²Œ ì œì‹œí•´ ì£¼ì„¸ìš”.\n\në‹µë³€: {user_answer}\n\ní‰ê°€ ë° í”¼ë“œë°±:"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë›°ì–´ë‚œ ë©´ì ‘ê´€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=200
    )
    return response.choices[0].message['content'].strip()
```
âœ… AIê°€ ë‹µë³€ì„ ë¶„ì„í•˜ê³ , ê°œì„ ì  ì¤‘ì‹¬ì˜ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.

### 3ï¸âƒ£ ë‹µë³€ ì ìˆ˜í™” í•¨ìˆ˜
```python
def score_answer(user_answer):
    prompt = f"ë‹¤ìŒ ë‹µë³€ì— ëŒ€í•´ 0~100ì ì˜ ì ìˆ˜ë¥¼ ë§¤ê¸°ê³ , í•œ ì¤„ë¡œ ì´ìœ ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\n\në‹µë³€: {user_answer}\n\nì ìˆ˜ì™€ ê°„ë‹¨í•œ ì½”ë©˜íŠ¸:"
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë›°ì–´ë‚œ ë©´ì ‘ê´€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=100
    )
    return response.choices[0].message['content'].strip()
```
âœ… ì ìˆ˜ì™€ í•¨ê»˜ ê°„ë‹¨í•œ í‰ê°€ ì½”ë©˜íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### 4ï¸âƒ£ Streamlit ì¸í„°í˜ì´ìŠ¤
```python
import streamlit as st

st.title("AI ë©´ì ‘ê´€ Agent")
user_intro = st.text_area("ìê¸°ì†Œê°œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
if st.button("ë©´ì ‘ ì‹œì‘"):
    question = generate_question(user_intro)
    st.write("ë©´ì ‘ê´€:", question)

    user_answer = st.text_area("ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”.", key="answer1")
    if st.button("ë‹µë³€ ì œì¶œ"):
        feedback = evaluate_answer(user_answer)
        score = score_answer(user_answer)
        st.write("í”¼ë“œë°±:", feedback)
        st.write("ì ìˆ˜:", score)
```
âœ… ì‚¬ìš©ìì™€ì˜ ì¸í„°ë™ì…˜ì„ ìœ„í•œ ì›¹ UI êµ¬ì„±
âœ… ë©´ì ‘ ì‹œì‘ â†’ ì§ˆë¬¸ ìƒì„± â†’ ë‹µë³€ ì…ë ¥ â†’ í”¼ë“œë°± ë° ì ìˆ˜ ì œê³µ

## ğŸ’¬ ì‹¤í–‰ ì˜ˆì‹œ
```plaintext
ë©´ì ‘ê´€: ì§€ì›ìë‹˜ì˜ ìê¸°ì†Œê°œë¥¼ ë“£ê³ , ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ê²½í—˜ì„ ìì„¸íˆ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?

ì§€ì›ì: ëŒ€í•™ ì‹œì ˆ ë™ì•„ë¦¬ í™œë™ì—ì„œ íŒ€ í”„ë¡œì íŠ¸ë¥¼ ì£¼ë„í•˜ë©°...

í”¼ë“œë°±: ê²½í—˜ì„ êµ¬ì²´ì ìœ¼ë¡œ ì˜ ì„¤ëª…í•˜ì…¨ìŠµë‹ˆë‹¤. ê²°ê³¼ì— ëŒ€í•œ ìˆ˜ì¹˜ë‚˜ ì„±ê³¼ë¥¼ ë”í•˜ë©´ ë” ì¢‹ê² ìŠµë‹ˆë‹¤.

ì ìˆ˜: 85/100 - ê²½í—˜ì´ ì˜ ë“œëŸ¬ë‚¨, êµ¬ì²´ì„± ë³´ì™„ í•„ìš”
## ğŸ“Š ì£¼ìš” ê²°ê³¼
ğŸ”¹ í”¼ë“œë°± ìš”ì•½í‘œ

ğŸ”¹ ì„œë¹„ìŠ¤ ì‹¤ì œ í™”ë©´

