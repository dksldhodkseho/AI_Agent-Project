# Step2_AIë©´ì ‘ê´€ Agent v2.0

> GPT ê¸°ë°˜ AI ë©´ì ‘ê´€ Agent: ì´ë ¥ì„œ ë¶„ì„ â†’ ì§ˆë¬¸ ìƒì„± â†’ ë‹µë³€ í‰ê°€ â†’ í”¼ë“œë°± ì œê³µ

---

## âœ… í”„ë¡œì íŠ¸ ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” GPT ê¸°ë°˜ ë©´ì ‘ ì‹œë®¬ë ˆì´í„° Agentë¥¼ êµ¬í˜„í•œ ê²ƒì…ë‹ˆë‹¤. ì£¼ìš” ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- ì´ë ¥ì„œ ë¶„ì„ (ìš”ì•½ + í‚¤ì›Œë“œ + íŠ¸ë¦¬ê±° í¬ì¸íŠ¸ ì¶”ì¶œ)
- ì§ˆë¬¸ ì „ëµ ìˆ˜ë¦½ ë° ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±
- ë‹µë³€ì— ëŒ€í•œ í‰ê°€ ë° í”¼ë“œë°±
- ì¸í„°ë·° íë¦„ ì œì–´ ë° ì¢…í•© í‰ê°€ ì œê³µ
- Gradio ì›¹ ì•± ì—°ë™

---

## ğŸ› ï¸ ì‚¬ìš© ê¸°ìˆ 

- Python (Google Colab)
- LangChain, LangGraph
- OpenAI GPT-4o-mini
- Gradio (HuggingFace)
- Chroma (Vector DB)
  
---

## ğŸ§  ì‹œìŠ¤í…œ êµ¬ì¡°

AI ë©´ì ‘ê´€ì˜ ì „ì²´ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

![ì‹œìŠ¤í…œ êµ¬ì¡°ë„](./ai_interview_pipeline.png)

> ìê¸°ì†Œê°œ â†’ AI ì§ˆë¬¸ ìƒì„± â†’ ë‹µë³€ ì…ë ¥ â†’ í”¼ë“œë°± ì œê³µ â†’ ì ìˆ˜í™”

---

## âš™ï¸ ì‹¤í–‰ ë°©ë²•

### 1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ë™

```python
from google.colab import drive
drive.mount('/content/drive')
```
### 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
```python
!pip install -r /content/drive/MyDrive/project_genai/requirements.txt
```
### 3. OpenAI API Key ì„¤ì •
api_key.txt íŒŒì¼ í˜•ì‹:
```python
OPENAI_API_KEY=your_api_key_here
```
Python ì½”ë“œë¡œ í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°:
```python
import os

def load_api_keys(filepath="api_key.txt"):
    with open(filepath, "r") as f:
        for line in f:
            if "=" in line:
                k, v = line.strip().split("=", 1)
                os.environ[k] = v

load_api_keys('/content/drive/MyDrive/project_genai/api_key.txt')
```
### 4. ì‹¤í–‰ ì˜ˆì‹œ
```python
filepath = '/content/drive/MyDrive/project_genai/Resume_sample.pdf'
state = preProcessing_Interview(filepath)

while True:
    print("[ì§ˆë¬¸]")
    print(state["current_question"])
    state["current_answer"] = input("[ë‹µë³€ ì…ë ¥]: ")
    state = graph.invoke(state)
    if state["next_step"] == "end":
        break
```
## ğŸŒ Gradio ì¸í„°í˜ì´ìŠ¤ ì˜ˆì‹œ
```python
import gradio as gr

def interview_run(file, answer):
    state = preProcessing_Interview(file.name)
    state["current_answer"] = answer
    state = graph.invoke(state)
    return state["current_question"], state["evaluation"][0]["í‰ê°€ì— ëŒ€í•œ ì´ìœ "]

iface = gr.Interface(
    fn=interview_run,
    inputs=["file", "textbox"],
    outputs=["text", "text"],
    title="AI ë©´ì ‘ê´€ Agent v2.0"
)

iface.launch()
```
## ğŸ“Œ ê³ ë„í™” í•µì‹¬ ê¸°ëŠ¥
âœ… Resume ë¶„ì„ ê³ ë„í™” (ìš”ì•½ + í‚¤ì›Œë“œ + ì¤‘ìš”ë„ + íŠ¸ë¦¬ê±° íƒì§€)

âœ… ì§ˆë¬¸ ì „ëµ 3ë¶„ì•¼ ì„¤ì • + Vector DB ìœ ì‚¬ì§ˆë¬¸ ì°¸ì¡°

âœ… ë‹µë³€ í‰ê°€ í›„ reflectionìœ¼ë¡œ í‰ê°€ í’ˆì§ˆ ê²€í† 

âœ… ì „ëµ ìˆœí™˜ ë°©ì‹ ë©´ì ‘ íë¦„ + í‰ê°€ê¸°ë°˜ ì¢…ë£Œ/ì‹¬í™” ì „í™˜

âœ… ì¢…í•© í”¼ë“œë°± ìë™ ìƒì„±

## ğŸ“ì°¸ê³  ê¸°ìˆ 
OpenAI GPT-4o-mini

LangChain, LangGraph

Gradio (HuggingFace)

Chroma Vector DB

## ğŸ’¬ ì‹¤í–‰ ì˜ˆì‹œ
```plaintext
ë©´ì ‘ê´€: ì§€ì›ìë‹˜ì˜ ìê¸°ì†Œê°œë¥¼ ë“£ê³ , ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ê²½í—˜ì„ ìì„¸íˆ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?

ì§€ì›ì: ëŒ€í•™ ì‹œì ˆ ë™ì•„ë¦¬ í™œë™ì—ì„œ íŒ€ í”„ë¡œì íŠ¸ë¥¼ ì£¼ë„í•˜ë©°...

í”¼ë“œë°±: ê²½í—˜ì„ êµ¬ì²´ì ìœ¼ë¡œ ì˜ ì„¤ëª…í•˜ì…¨ìŠµë‹ˆë‹¤. ê²°ê³¼ì— ëŒ€í•œ ìˆ˜ì¹˜ë‚˜ ì„±ê³¼ë¥¼ ë”í•˜ë©´ ë” ì¢‹ê² ìŠµë‹ˆë‹¤.

ì ìˆ˜: 85/100 - ê²½í—˜ì´ ì˜ ë“œëŸ¬ë‚¨, êµ¬ì²´ì„± ë³´ì™„ í•„ìš”
```
## ğŸ“Š ì‹¤ì œ ì„œë¹„ìŠ¤ í™”ë©´
![ì„œë¹„ìŠ¤ ì‹¤ì œ í™”ë©´](./ai_interview_ui.png)

